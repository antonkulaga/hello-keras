{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "import keras\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, SparsePCA\n",
    "import pandas as pd\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Eugen stuff\n",
    "import sklearn.svm\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "samples = pq.read_table('/data/gtex/samples.parquet').to_pandas()\n",
    "genes = pd.read_csv(\"/data/gtex/genage_gtex.tsv\", sep=\"\\t\", index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Name</th>\n",
       "      <th>ENSG00000198804</th>\n",
       "      <th>ENSG00000196689</th>\n",
       "      <th>ENSG00000170899</th>\n",
       "      <th>ENSG00000259384</th>\n",
       "      <th>ENSG00000096968</th>\n",
       "      <th>ENSG00000112964</th>\n",
       "      <th>ENSG00000100311</th>\n",
       "      <th>ENSG00000127445</th>\n",
       "      <th>ENSG00000141837</th>\n",
       "      <th>ENSG00000118432</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000073756</th>\n",
       "      <th>ENSG00000143252</th>\n",
       "      <th>ENSG00000115966</th>\n",
       "      <th>ENSG00000169047</th>\n",
       "      <th>ENSG00000183395</th>\n",
       "      <th>ENSG00000017427</th>\n",
       "      <th>ENSG00000177606</th>\n",
       "      <th>ENSG00000164104</th>\n",
       "      <th>ENSG00000160957</th>\n",
       "      <th>ENSG00000059728</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GTEX-1117F-0226-SM-5GZZ7</th>\n",
       "      <td>10660.0</td>\n",
       "      <td>20.67</td>\n",
       "      <td>24.83</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>23.78</td>\n",
       "      <td>37.70</td>\n",
       "      <td>23.76</td>\n",
       "      <td>37.33</td>\n",
       "      <td>0.6694</td>\n",
       "      <td>6.685</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1360</td>\n",
       "      <td>43.67</td>\n",
       "      <td>23.13</td>\n",
       "      <td>11.47</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>40.63</td>\n",
       "      <td>526.4</td>\n",
       "      <td>139.50</td>\n",
       "      <td>3.667</td>\n",
       "      <td>16.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-111CU-1826-SM-5GZYN</th>\n",
       "      <td>11060.0</td>\n",
       "      <td>10.58</td>\n",
       "      <td>17.71</td>\n",
       "      <td>0.4593</td>\n",
       "      <td>21.51</td>\n",
       "      <td>73.55</td>\n",
       "      <td>34.54</td>\n",
       "      <td>42.96</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>29.800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5251</td>\n",
       "      <td>71.07</td>\n",
       "      <td>22.71</td>\n",
       "      <td>10.37</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>68.23</td>\n",
       "      <td>256.6</td>\n",
       "      <td>95.25</td>\n",
       "      <td>3.141</td>\n",
       "      <td>12.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-111FC-0226-SM-5N9B8</th>\n",
       "      <td>21320.0</td>\n",
       "      <td>15.66</td>\n",
       "      <td>30.25</td>\n",
       "      <td>4.6720</td>\n",
       "      <td>22.64</td>\n",
       "      <td>23.37</td>\n",
       "      <td>70.91</td>\n",
       "      <td>38.26</td>\n",
       "      <td>1.9000</td>\n",
       "      <td>10.750</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1170</td>\n",
       "      <td>56.96</td>\n",
       "      <td>32.70</td>\n",
       "      <td>13.02</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24.38</td>\n",
       "      <td>519.3</td>\n",
       "      <td>76.09</td>\n",
       "      <td>3.941</td>\n",
       "      <td>8.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-111VG-2326-SM-5N9BK</th>\n",
       "      <td>19850.0</td>\n",
       "      <td>12.31</td>\n",
       "      <td>16.50</td>\n",
       "      <td>4.8020</td>\n",
       "      <td>19.02</td>\n",
       "      <td>15.95</td>\n",
       "      <td>41.83</td>\n",
       "      <td>33.27</td>\n",
       "      <td>0.7103</td>\n",
       "      <td>1.704</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1840</td>\n",
       "      <td>52.94</td>\n",
       "      <td>21.67</td>\n",
       "      <td>5.35</td>\n",
       "      <td>0.1227</td>\n",
       "      <td>29.26</td>\n",
       "      <td>871.3</td>\n",
       "      <td>69.30</td>\n",
       "      <td>5.417</td>\n",
       "      <td>37.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-111YS-2426-SM-5GZZQ</th>\n",
       "      <td>31260.0</td>\n",
       "      <td>6.76</td>\n",
       "      <td>16.79</td>\n",
       "      <td>5.4420</td>\n",
       "      <td>31.18</td>\n",
       "      <td>116.20</td>\n",
       "      <td>71.35</td>\n",
       "      <td>27.91</td>\n",
       "      <td>1.0790</td>\n",
       "      <td>26.620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3932</td>\n",
       "      <td>44.61</td>\n",
       "      <td>23.08</td>\n",
       "      <td>10.55</td>\n",
       "      <td>0.8340</td>\n",
       "      <td>33.65</td>\n",
       "      <td>175.3</td>\n",
       "      <td>98.29</td>\n",
       "      <td>2.780</td>\n",
       "      <td>9.886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Name                      ENSG00000198804  ENSG00000196689  ENSG00000170899  \\\n",
       "GTEX-1117F-0226-SM-5GZZ7          10660.0            20.67            24.83   \n",
       "GTEX-111CU-1826-SM-5GZYN          11060.0            10.58            17.71   \n",
       "GTEX-111FC-0226-SM-5N9B8          21320.0            15.66            30.25   \n",
       "GTEX-111VG-2326-SM-5N9BK          19850.0            12.31            16.50   \n",
       "GTEX-111YS-2426-SM-5GZZQ          31260.0             6.76            16.79   \n",
       "\n",
       "Name                      ENSG00000259384  ENSG00000096968  ENSG00000112964  \\\n",
       "GTEX-1117F-0226-SM-5GZZ7           0.2450            23.78            37.70   \n",
       "GTEX-111CU-1826-SM-5GZYN           0.4593            21.51            73.55   \n",
       "GTEX-111FC-0226-SM-5N9B8           4.6720            22.64            23.37   \n",
       "GTEX-111VG-2326-SM-5N9BK           4.8020            19.02            15.95   \n",
       "GTEX-111YS-2426-SM-5GZZQ           5.4420            31.18           116.20   \n",
       "\n",
       "Name                      ENSG00000100311  ENSG00000127445  ENSG00000141837  \\\n",
       "GTEX-1117F-0226-SM-5GZZ7            23.76            37.33           0.6694   \n",
       "GTEX-111CU-1826-SM-5GZYN            34.54            42.96           1.0900   \n",
       "GTEX-111FC-0226-SM-5N9B8            70.91            38.26           1.9000   \n",
       "GTEX-111VG-2326-SM-5N9BK            41.83            33.27           0.7103   \n",
       "GTEX-111YS-2426-SM-5GZZQ            71.35            27.91           1.0790   \n",
       "\n",
       "Name                      ENSG00000118432  ...  ENSG00000073756  \\\n",
       "GTEX-1117F-0226-SM-5GZZ7            6.685  ...           2.1360   \n",
       "GTEX-111CU-1826-SM-5GZYN           29.800  ...           0.5251   \n",
       "GTEX-111FC-0226-SM-5N9B8           10.750  ...           1.1170   \n",
       "GTEX-111VG-2326-SM-5N9BK            1.704  ...           6.1840   \n",
       "GTEX-111YS-2426-SM-5GZZQ           26.620  ...           0.3932   \n",
       "\n",
       "Name                      ENSG00000143252  ENSG00000115966  ENSG00000169047  \\\n",
       "GTEX-1117F-0226-SM-5GZZ7            43.67            23.13            11.47   \n",
       "GTEX-111CU-1826-SM-5GZYN            71.07            22.71            10.37   \n",
       "GTEX-111FC-0226-SM-5N9B8            56.96            32.70            13.02   \n",
       "GTEX-111VG-2326-SM-5N9BK            52.94            21.67             5.35   \n",
       "GTEX-111YS-2426-SM-5GZZQ            44.61            23.08            10.55   \n",
       "\n",
       "Name                      ENSG00000183395  ENSG00000017427  ENSG00000177606  \\\n",
       "GTEX-1117F-0226-SM-5GZZ7           0.1898            40.63            526.4   \n",
       "GTEX-111CU-1826-SM-5GZYN           0.4575            68.23            256.6   \n",
       "GTEX-111FC-0226-SM-5N9B8           0.0000            24.38            519.3   \n",
       "GTEX-111VG-2326-SM-5N9BK           0.1227            29.26            871.3   \n",
       "GTEX-111YS-2426-SM-5GZZQ           0.8340            33.65            175.3   \n",
       "\n",
       "Name                      ENSG00000164104  ENSG00000160957  ENSG00000059728  \n",
       "GTEX-1117F-0226-SM-5GZZ7           139.50            3.667           16.590  \n",
       "GTEX-111CU-1826-SM-5GZYN            95.25            3.141           12.520  \n",
       "GTEX-111FC-0226-SM-5N9B8            76.09            3.941            8.683  \n",
       "GTEX-111VG-2326-SM-5N9BK            69.30            5.417           37.350  \n",
       "GTEX-111YS-2426-SM-5GZZQ            98.29            2.780            9.886  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = genes.T\n",
    "data.columns.names = [\"Name\"]\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Tissue</th>\n",
       "      <th>Subtissue</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Death</th>\n",
       "      <th>Avg_age</th>\n",
       "      <th>ENSG00000198804</th>\n",
       "      <th>ENSG00000196689</th>\n",
       "      <th>ENSG00000170899</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000073756</th>\n",
       "      <th>ENSG00000143252</th>\n",
       "      <th>ENSG00000115966</th>\n",
       "      <th>ENSG00000169047</th>\n",
       "      <th>ENSG00000183395</th>\n",
       "      <th>ENSG00000017427</th>\n",
       "      <th>ENSG00000177606</th>\n",
       "      <th>ENSG00000164104</th>\n",
       "      <th>ENSG00000160957</th>\n",
       "      <th>ENSG00000059728</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GTEX-11O72-2926-SM-5BC4V</th>\n",
       "      <td>GTEX-11O72</td>\n",
       "      <td>Brain</td>\n",
       "      <td>Brain - Cortex</td>\n",
       "      <td>1</td>\n",
       "      <td>40-49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>80890.0</td>\n",
       "      <td>5.281</td>\n",
       "      <td>34.110</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3410</td>\n",
       "      <td>20.27</td>\n",
       "      <td>19.450</td>\n",
       "      <td>2.518</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.47010</td>\n",
       "      <td>93.79</td>\n",
       "      <td>21.86</td>\n",
       "      <td>6.599</td>\n",
       "      <td>8.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-11TTK-0008-SM-5S2RU</th>\n",
       "      <td>GTEX-11TTK</td>\n",
       "      <td>Skin</td>\n",
       "      <td>Cells - Transformed fibroblasts</td>\n",
       "      <td>2</td>\n",
       "      <td>60-69</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>23710.0</td>\n",
       "      <td>4.964</td>\n",
       "      <td>43.160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8661</td>\n",
       "      <td>121.50</td>\n",
       "      <td>26.410</td>\n",
       "      <td>40.600</td>\n",
       "      <td>0.1677</td>\n",
       "      <td>0.08062</td>\n",
       "      <td>81.60</td>\n",
       "      <td>143.90</td>\n",
       "      <td>6.836</td>\n",
       "      <td>2.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-11UD2-0226-SM-5EQKY</th>\n",
       "      <td>GTEX-11UD2</td>\n",
       "      <td>Skin</td>\n",
       "      <td>Skin - Sun Exposed (Lower leg)</td>\n",
       "      <td>1</td>\n",
       "      <td>50-59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.5</td>\n",
       "      <td>31680.0</td>\n",
       "      <td>5.967</td>\n",
       "      <td>65.190</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8050</td>\n",
       "      <td>54.38</td>\n",
       "      <td>9.462</td>\n",
       "      <td>8.703</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>1.18900</td>\n",
       "      <td>302.20</td>\n",
       "      <td>53.00</td>\n",
       "      <td>5.655</td>\n",
       "      <td>22.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-12KS4-0005-SM-5SI94</th>\n",
       "      <td>GTEX-12KS4</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Whole Blood</td>\n",
       "      <td>1</td>\n",
       "      <td>30-39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>3867.0</td>\n",
       "      <td>1.801</td>\n",
       "      <td>1.044</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1800</td>\n",
       "      <td>35.87</td>\n",
       "      <td>9.118</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.32690</td>\n",
       "      <td>100.40</td>\n",
       "      <td>165.60</td>\n",
       "      <td>6.525</td>\n",
       "      <td>737.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEX-131XE-2526-SM-5EQ57</th>\n",
       "      <td>GTEX-131XE</td>\n",
       "      <td>Nerve</td>\n",
       "      <td>Nerve - Tibial</td>\n",
       "      <td>1</td>\n",
       "      <td>50-59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.5</td>\n",
       "      <td>12650.0</td>\n",
       "      <td>12.470</td>\n",
       "      <td>32.010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3920</td>\n",
       "      <td>69.37</td>\n",
       "      <td>25.880</td>\n",
       "      <td>10.210</td>\n",
       "      <td>0.3869</td>\n",
       "      <td>11.71000</td>\n",
       "      <td>535.00</td>\n",
       "      <td>97.57</td>\n",
       "      <td>12.400</td>\n",
       "      <td>16.790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Subject Tissue                        Subtissue  \\\n",
       "Name                                                                           \n",
       "GTEX-11O72-2926-SM-5BC4V  GTEX-11O72  Brain                   Brain - Cortex   \n",
       "GTEX-11TTK-0008-SM-5S2RU  GTEX-11TTK   Skin  Cells - Transformed fibroblasts   \n",
       "GTEX-11UD2-0226-SM-5EQKY  GTEX-11UD2   Skin   Skin - Sun Exposed (Lower leg)   \n",
       "GTEX-12KS4-0005-SM-5SI94  GTEX-12KS4  Blood                      Whole Blood   \n",
       "GTEX-131XE-2526-SM-5EQ57  GTEX-131XE  Nerve                   Nerve - Tibial   \n",
       "\n",
       "                          Sex    Age  Death  Avg_age  ENSG00000198804  \\\n",
       "Name                                                                    \n",
       "GTEX-11O72-2926-SM-5BC4V    1  40-49    2.0     44.5          80890.0   \n",
       "GTEX-11TTK-0008-SM-5S2RU    2  60-69    4.0     64.5          23710.0   \n",
       "GTEX-11UD2-0226-SM-5EQKY    1  50-59    2.0     54.5          31680.0   \n",
       "GTEX-12KS4-0005-SM-5SI94    1  30-39    0.0     34.5           3867.0   \n",
       "GTEX-131XE-2526-SM-5EQ57    1  50-59    0.0     54.5          12650.0   \n",
       "\n",
       "                          ENSG00000196689  ENSG00000170899  ...  \\\n",
       "Name                                                        ...   \n",
       "GTEX-11O72-2926-SM-5BC4V            5.281           34.110  ...   \n",
       "GTEX-11TTK-0008-SM-5S2RU            4.964           43.160  ...   \n",
       "GTEX-11UD2-0226-SM-5EQKY            5.967           65.190  ...   \n",
       "GTEX-12KS4-0005-SM-5SI94            1.801            1.044  ...   \n",
       "GTEX-131XE-2526-SM-5EQ57           12.470           32.010  ...   \n",
       "\n",
       "                          ENSG00000073756  ENSG00000143252  ENSG00000115966  \\\n",
       "Name                                                                          \n",
       "GTEX-11O72-2926-SM-5BC4V           4.3410            20.27           19.450   \n",
       "GTEX-11TTK-0008-SM-5S2RU           0.8661           121.50           26.410   \n",
       "GTEX-11UD2-0226-SM-5EQKY           4.8050            54.38            9.462   \n",
       "GTEX-12KS4-0005-SM-5SI94          10.1800            35.87            9.118   \n",
       "GTEX-131XE-2526-SM-5EQ57           1.3920            69.37           25.880   \n",
       "\n",
       "                          ENSG00000169047  ENSG00000183395  ENSG00000017427  \\\n",
       "Name                                                                          \n",
       "GTEX-11O72-2926-SM-5BC4V            2.518           0.0000          0.47010   \n",
       "GTEX-11TTK-0008-SM-5S2RU           40.600           0.1677          0.08062   \n",
       "GTEX-11UD2-0226-SM-5EQKY            8.703           0.1313          1.18900   \n",
       "GTEX-12KS4-0005-SM-5SI94            0.215           0.0000          0.32690   \n",
       "GTEX-131XE-2526-SM-5EQ57           10.210           0.3869         11.71000   \n",
       "\n",
       "                          ENSG00000177606  ENSG00000164104  ENSG00000160957  \\\n",
       "Name                                                                          \n",
       "GTEX-11O72-2926-SM-5BC4V            93.79            21.86            6.599   \n",
       "GTEX-11TTK-0008-SM-5S2RU            81.60           143.90            6.836   \n",
       "GTEX-11UD2-0226-SM-5EQKY           302.20            53.00            5.655   \n",
       "GTEX-12KS4-0005-SM-5SI94           100.40           165.60            6.525   \n",
       "GTEX-131XE-2526-SM-5EQ57           535.00            97.57           12.400   \n",
       "\n",
       "                          ENSG00000059728  \n",
       "Name                                       \n",
       "GTEX-11O72-2926-SM-5BC4V            8.137  \n",
       "GTEX-11TTK-0008-SM-5S2RU            2.439  \n",
       "GTEX-11UD2-0226-SM-5EQKY           22.060  \n",
       "GTEX-12KS4-0005-SM-5SI94          737.900  \n",
       "GTEX-131XE-2526-SM-5EQ57           16.790  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = samples.set_index(\"Name\")\n",
    "j = samples.join(data)\n",
    "j.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ji = j.columns.drop([\"Subject\", \"Tissue\", \"Subtissue\", \"Sex\", \"Age\", \"Death\", \"Avg_age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = j[\"Avg_age\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = j[ji].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = keras.utils.normalize(X,axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(x, Y.reshape(Y.shape[0],1), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9350, 297)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 64)                19072     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 24)                1176      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 23,681\n",
      "Trainable params: 23,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=trainX.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(48, input_dim=trainX.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(24, input_dim=trainX.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(12, activation=\"relu\"))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n"
     ]
    }
   ],
   "source": [
    "# initialize our initial learning rate and # of epochs to train for\n",
    "INIT_LR = 0.07\n",
    "EPOCHS = 400\n",
    "\n",
    "# compile the model using SGD as our optimizer and categorical\n",
    "# cross-entropy loss (you'll want to use binary_crossentropy\n",
    "# for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9350 samples, validate on 2338 samples\n",
      "Epoch 1/400\n",
      "9350/9350 [==============================] - 1s 75us/step - loss: 2918.9550 - mean_squared_error: 2918.9550 - val_loss: 2718.8330 - val_mean_squared_error: 2718.8330\n",
      "Epoch 2/400\n",
      "9350/9350 [==============================] - 0s 10us/step - loss: 2235.7342 - mean_squared_error: 2235.7342 - val_loss: 1103.2457 - val_mean_squared_error: 1103.2457\n",
      "Epoch 3/400\n",
      "9350/9350 [==============================] - 0s 10us/step - loss: 487.5827 - mean_squared_error: 487.5827 - val_loss: 297.5249 - val_mean_squared_error: 297.5249\n",
      "Epoch 4/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 315.0939 - mean_squared_error: 315.0939 - val_loss: 268.4393 - val_mean_squared_error: 268.4393\n",
      "Epoch 5/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 282.3030 - mean_squared_error: 282.3030 - val_loss: 236.8896 - val_mean_squared_error: 236.8896\n",
      "Epoch 6/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 254.9343 - mean_squared_error: 254.9343 - val_loss: 208.1089 - val_mean_squared_error: 208.1089\n",
      "Epoch 7/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 228.9575 - mean_squared_error: 228.9575 - val_loss: 186.2022 - val_mean_squared_error: 186.2022\n",
      "Epoch 8/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 210.2373 - mean_squared_error: 210.2373 - val_loss: 172.2440 - val_mean_squared_error: 172.2440\n",
      "Epoch 9/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 204.2499 - mean_squared_error: 204.2499 - val_loss: 164.2332 - val_mean_squared_error: 164.2332\n",
      "Epoch 10/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 189.5888 - mean_squared_error: 189.5888 - val_loss: 159.9544 - val_mean_squared_error: 159.9544\n",
      "Epoch 11/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 183.5392 - mean_squared_error: 183.5392 - val_loss: 156.9831 - val_mean_squared_error: 156.9831\n",
      "Epoch 12/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 183.3557 - mean_squared_error: 183.3557 - val_loss: 154.8476 - val_mean_squared_error: 154.8476\n",
      "Epoch 13/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 179.6868 - mean_squared_error: 179.6868 - val_loss: 155.1731 - val_mean_squared_error: 155.1731\n",
      "Epoch 14/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 177.1546 - mean_squared_error: 177.1546 - val_loss: 151.2893 - val_mean_squared_error: 151.2893\n",
      "Epoch 15/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 176.0980 - mean_squared_error: 176.0980 - val_loss: 150.2114 - val_mean_squared_error: 150.2114\n",
      "Epoch 16/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 175.0270 - mean_squared_error: 175.0270 - val_loss: 149.4309 - val_mean_squared_error: 149.4309\n",
      "Epoch 17/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 174.4976 - mean_squared_error: 174.4976 - val_loss: 148.5868 - val_mean_squared_error: 148.5868\n",
      "Epoch 18/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 173.3185 - mean_squared_error: 173.3185 - val_loss: 149.3656 - val_mean_squared_error: 149.3656\n",
      "Epoch 19/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 172.9018 - mean_squared_error: 172.9018 - val_loss: 148.1826 - val_mean_squared_error: 148.1826\n",
      "Epoch 20/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 171.8326 - mean_squared_error: 171.8326 - val_loss: 147.4013 - val_mean_squared_error: 147.4013\n",
      "Epoch 21/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 169.8620 - mean_squared_error: 169.8620 - val_loss: 146.7409 - val_mean_squared_error: 146.7409\n",
      "Epoch 22/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 169.2577 - mean_squared_error: 169.2577 - val_loss: 147.5539 - val_mean_squared_error: 147.5539\n",
      "Epoch 23/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 167.3536 - mean_squared_error: 167.3536 - val_loss: 146.3142 - val_mean_squared_error: 146.3142\n",
      "Epoch 24/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 164.8502 - mean_squared_error: 164.8502 - val_loss: 145.3983 - val_mean_squared_error: 145.3983\n",
      "Epoch 25/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 165.5283 - mean_squared_error: 165.5283 - val_loss: 147.0848 - val_mean_squared_error: 147.0848\n",
      "Epoch 26/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 164.7555 - mean_squared_error: 164.7555 - val_loss: 145.0626 - val_mean_squared_error: 145.0626\n",
      "Epoch 27/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 162.0198 - mean_squared_error: 162.0198 - val_loss: 145.6076 - val_mean_squared_error: 145.6076\n",
      "Epoch 28/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 165.2665 - mean_squared_error: 165.2665 - val_loss: 144.5637 - val_mean_squared_error: 144.5637\n",
      "Epoch 29/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 165.8815 - mean_squared_error: 165.8815 - val_loss: 145.6357 - val_mean_squared_error: 145.6357\n",
      "Epoch 30/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 163.7495 - mean_squared_error: 163.7495 - val_loss: 144.5194 - val_mean_squared_error: 144.5194\n",
      "Epoch 31/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 166.7206 - mean_squared_error: 166.7206 - val_loss: 144.6148 - val_mean_squared_error: 144.6148\n",
      "Epoch 32/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 163.2455 - mean_squared_error: 163.2455 - val_loss: 144.1057 - val_mean_squared_error: 144.1057\n",
      "Epoch 33/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 162.3074 - mean_squared_error: 162.3074 - val_loss: 144.6787 - val_mean_squared_error: 144.6787\n",
      "Epoch 34/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 163.4183 - mean_squared_error: 163.4183 - val_loss: 144.2626 - val_mean_squared_error: 144.2626\n",
      "Epoch 35/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 161.5370 - mean_squared_error: 161.5370 - val_loss: 143.4395 - val_mean_squared_error: 143.4395\n",
      "Epoch 36/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 160.3491 - mean_squared_error: 160.3491 - val_loss: 143.1450 - val_mean_squared_error: 143.1450\n",
      "Epoch 37/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 163.8874 - mean_squared_error: 163.8874 - val_loss: 143.4687 - val_mean_squared_error: 143.4687\n",
      "Epoch 38/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 161.0912 - mean_squared_error: 161.0912 - val_loss: 147.0788 - val_mean_squared_error: 147.0788\n",
      "Epoch 39/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 160.9466 - mean_squared_error: 160.9466 - val_loss: 142.8552 - val_mean_squared_error: 142.8552\n",
      "Epoch 40/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 161.7349 - mean_squared_error: 161.7349 - val_loss: 142.4584 - val_mean_squared_error: 142.4584\n",
      "Epoch 41/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 159.7672 - mean_squared_error: 159.7672 - val_loss: 144.3805 - val_mean_squared_error: 144.3805\n",
      "Epoch 42/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 158.8932 - mean_squared_error: 158.8932 - val_loss: 145.3805 - val_mean_squared_error: 145.3805\n",
      "Epoch 43/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 160.4851 - mean_squared_error: 160.4851 - val_loss: 146.3252 - val_mean_squared_error: 146.3252\n",
      "Epoch 44/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 156.4605 - mean_squared_error: 156.4605 - val_loss: 142.2988 - val_mean_squared_error: 142.2988\n",
      "Epoch 45/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 158.4203 - mean_squared_error: 158.4203 - val_loss: 144.0815 - val_mean_squared_error: 144.0815\n",
      "Epoch 46/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 158.3880 - mean_squared_error: 158.3880 - val_loss: 146.2286 - val_mean_squared_error: 146.2286\n",
      "Epoch 47/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 157.9900 - mean_squared_error: 157.9900 - val_loss: 141.9942 - val_mean_squared_error: 141.9942\n",
      "Epoch 48/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 157.4737 - mean_squared_error: 157.4737 - val_loss: 143.7425 - val_mean_squared_error: 143.7425\n",
      "Epoch 49/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 155.2574 - mean_squared_error: 155.2574 - val_loss: 145.9557 - val_mean_squared_error: 145.9557\n",
      "Epoch 50/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 155.2394 - mean_squared_error: 155.2394 - val_loss: 142.7955 - val_mean_squared_error: 142.7955\n",
      "Epoch 51/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 155.7221 - mean_squared_error: 155.7221 - val_loss: 144.6751 - val_mean_squared_error: 144.6751\n",
      "Epoch 52/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 154.1938 - mean_squared_error: 154.1938 - val_loss: 143.0556 - val_mean_squared_error: 143.0556\n",
      "Epoch 53/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 153.0101 - mean_squared_error: 153.0101 - val_loss: 141.9925 - val_mean_squared_error: 141.9925\n",
      "Epoch 54/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 155.8447 - mean_squared_error: 155.8447 - val_loss: 143.8950 - val_mean_squared_error: 143.8950\n",
      "Epoch 55/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 153.6177 - mean_squared_error: 153.6177 - val_loss: 143.1214 - val_mean_squared_error: 143.1214\n",
      "Epoch 56/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 156.2237 - mean_squared_error: 156.2237 - val_loss: 145.9425 - val_mean_squared_error: 145.9425\n",
      "Epoch 57/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 153.7892 - mean_squared_error: 153.7892 - val_loss: 144.0489 - val_mean_squared_error: 144.0489\n",
      "Epoch 58/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 153.8051 - mean_squared_error: 153.8051 - val_loss: 143.8604 - val_mean_squared_error: 143.8604\n",
      "Epoch 59/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 151.5632 - mean_squared_error: 151.5632 - val_loss: 142.5334 - val_mean_squared_error: 142.5334\n",
      "Epoch 60/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 153.7176 - mean_squared_error: 153.7176 - val_loss: 141.4466 - val_mean_squared_error: 141.4466\n",
      "Epoch 61/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 152.3803 - mean_squared_error: 152.3803 - val_loss: 143.5729 - val_mean_squared_error: 143.5729\n",
      "Epoch 62/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 150.7950 - mean_squared_error: 150.7950 - val_loss: 144.3473 - val_mean_squared_error: 144.3473\n",
      "Epoch 63/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 153.2958 - mean_squared_error: 153.2958 - val_loss: 142.5105 - val_mean_squared_error: 142.5105\n",
      "Epoch 64/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 148.9474 - mean_squared_error: 148.9474 - val_loss: 144.9999 - val_mean_squared_error: 144.9999\n",
      "Epoch 65/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 150.1577 - mean_squared_error: 150.1577 - val_loss: 149.2892 - val_mean_squared_error: 149.2892\n",
      "Epoch 66/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 149.1023 - mean_squared_error: 149.1023 - val_loss: 142.0695 - val_mean_squared_error: 142.0695\n",
      "Epoch 67/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 148.8887 - mean_squared_error: 148.8887 - val_loss: 148.9412 - val_mean_squared_error: 148.9412\n",
      "Epoch 68/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 150.0190 - mean_squared_error: 150.0190 - val_loss: 142.0680 - val_mean_squared_error: 142.0680\n",
      "Epoch 69/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 149.5953 - mean_squared_error: 149.5953 - val_loss: 145.4745 - val_mean_squared_error: 145.4745\n",
      "Epoch 70/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 147.3313 - mean_squared_error: 147.3313 - val_loss: 149.4844 - val_mean_squared_error: 149.4844\n",
      "Epoch 71/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 147.0615 - mean_squared_error: 147.0615 - val_loss: 144.8388 - val_mean_squared_error: 144.8388\n",
      "Epoch 72/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 147.1861 - mean_squared_error: 147.1861 - val_loss: 148.5565 - val_mean_squared_error: 148.5565\n",
      "Epoch 73/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 150.0690 - mean_squared_error: 150.0690 - val_loss: 144.1885 - val_mean_squared_error: 144.1885\n",
      "Epoch 74/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 148.0342 - mean_squared_error: 148.0342 - val_loss: 149.2099 - val_mean_squared_error: 149.2099\n",
      "Epoch 75/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 147.0694 - mean_squared_error: 147.0694 - val_loss: 150.1611 - val_mean_squared_error: 150.1611\n",
      "Epoch 76/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 147.1851 - mean_squared_error: 147.1851 - val_loss: 145.8327 - val_mean_squared_error: 145.8327\n",
      "Epoch 77/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 147.0176 - mean_squared_error: 147.0176 - val_loss: 143.3873 - val_mean_squared_error: 143.3873\n",
      "Epoch 78/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 144.4241 - mean_squared_error: 144.4241 - val_loss: 146.4646 - val_mean_squared_error: 146.4646\n",
      "Epoch 79/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 144.8704 - mean_squared_error: 144.8704 - val_loss: 144.1207 - val_mean_squared_error: 144.1207\n",
      "Epoch 80/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 145.0582 - mean_squared_error: 145.0582 - val_loss: 151.0275 - val_mean_squared_error: 151.0275\n",
      "Epoch 81/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 144.0325 - mean_squared_error: 144.0325 - val_loss: 149.1699 - val_mean_squared_error: 149.1699\n",
      "Epoch 82/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 143.6805 - mean_squared_error: 143.6805 - val_loss: 145.9754 - val_mean_squared_error: 145.9754\n",
      "Epoch 83/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 144.4318 - mean_squared_error: 144.4318 - val_loss: 150.7702 - val_mean_squared_error: 150.7702\n",
      "Epoch 84/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 143.1817 - mean_squared_error: 143.1817 - val_loss: 141.0810 - val_mean_squared_error: 141.0810\n",
      "Epoch 85/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 143.8098 - mean_squared_error: 143.8098 - val_loss: 148.9791 - val_mean_squared_error: 148.9791\n",
      "Epoch 86/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 141.7576 - mean_squared_error: 141.7576 - val_loss: 147.8260 - val_mean_squared_error: 147.8260\n",
      "Epoch 87/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 141.8739 - mean_squared_error: 141.8739 - val_loss: 147.3966 - val_mean_squared_error: 147.3966\n",
      "Epoch 88/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 141.5507 - mean_squared_error: 141.5507 - val_loss: 145.8918 - val_mean_squared_error: 145.8918\n",
      "Epoch 89/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 139.1217 - mean_squared_error: 139.1217 - val_loss: 146.9110 - val_mean_squared_error: 146.9110\n",
      "Epoch 90/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 141.8898 - mean_squared_error: 141.8898 - val_loss: 142.8769 - val_mean_squared_error: 142.8769\n",
      "Epoch 91/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 141.4475 - mean_squared_error: 141.4475 - val_loss: 143.4095 - val_mean_squared_error: 143.4095\n",
      "Epoch 92/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 139.3419 - mean_squared_error: 139.3419 - val_loss: 144.4885 - val_mean_squared_error: 144.4885\n",
      "Epoch 93/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 141.3223 - mean_squared_error: 141.3223 - val_loss: 137.7380 - val_mean_squared_error: 137.7380\n",
      "Epoch 94/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 140.0660 - mean_squared_error: 140.0660 - val_loss: 151.8281 - val_mean_squared_error: 151.8281\n",
      "Epoch 95/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 141.4104 - mean_squared_error: 141.4104 - val_loss: 151.0323 - val_mean_squared_error: 151.0323\n",
      "Epoch 96/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 138.5230 - mean_squared_error: 138.5230 - val_loss: 147.7431 - val_mean_squared_error: 147.7431\n",
      "Epoch 97/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 137.9209 - mean_squared_error: 137.9209 - val_loss: 147.8535 - val_mean_squared_error: 147.8535\n",
      "Epoch 98/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 139.2503 - mean_squared_error: 139.2503 - val_loss: 153.5385 - val_mean_squared_error: 153.5385\n",
      "Epoch 99/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 138.1513 - mean_squared_error: 138.1513 - val_loss: 147.6322 - val_mean_squared_error: 147.6322\n",
      "Epoch 100/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 138.7183 - mean_squared_error: 138.7183 - val_loss: 144.1449 - val_mean_squared_error: 144.1449\n",
      "Epoch 101/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 140.1847 - mean_squared_error: 140.1847 - val_loss: 159.5879 - val_mean_squared_error: 159.5879\n",
      "Epoch 102/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 137.7121 - mean_squared_error: 137.7121 - val_loss: 156.6373 - val_mean_squared_error: 156.6373\n",
      "Epoch 103/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 138.8317 - mean_squared_error: 138.8317 - val_loss: 143.0929 - val_mean_squared_error: 143.0929\n",
      "Epoch 104/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 138.9258 - mean_squared_error: 138.9258 - val_loss: 141.4253 - val_mean_squared_error: 141.4253\n",
      "Epoch 105/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 138.3340 - mean_squared_error: 138.3340 - val_loss: 152.9715 - val_mean_squared_error: 152.9715\n",
      "Epoch 106/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 135.5019 - mean_squared_error: 135.5019 - val_loss: 141.6230 - val_mean_squared_error: 141.6230\n",
      "Epoch 107/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 135.7068 - mean_squared_error: 135.7068 - val_loss: 158.5427 - val_mean_squared_error: 158.5427\n",
      "Epoch 108/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 135.3745 - mean_squared_error: 135.3745 - val_loss: 149.5254 - val_mean_squared_error: 149.5254\n",
      "Epoch 109/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 136.1583 - mean_squared_error: 136.1583 - val_loss: 149.4700 - val_mean_squared_error: 149.4700\n",
      "Epoch 110/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 134.6622 - mean_squared_error: 134.6622 - val_loss: 146.6526 - val_mean_squared_error: 146.6526\n",
      "Epoch 111/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 134.6905 - mean_squared_error: 134.6905 - val_loss: 155.4693 - val_mean_squared_error: 155.4693\n",
      "Epoch 112/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 135.8817 - mean_squared_error: 135.8817 - val_loss: 161.6448 - val_mean_squared_error: 161.6448\n",
      "Epoch 113/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 135.7054 - mean_squared_error: 135.7054 - val_loss: 154.2126 - val_mean_squared_error: 154.2126\n",
      "Epoch 114/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 133.7300 - mean_squared_error: 133.7300 - val_loss: 151.7293 - val_mean_squared_error: 151.7293\n",
      "Epoch 115/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 133.7781 - mean_squared_error: 133.7781 - val_loss: 147.8438 - val_mean_squared_error: 147.8438\n",
      "Epoch 116/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 135.9048 - mean_squared_error: 135.9048 - val_loss: 145.5602 - val_mean_squared_error: 145.5602\n",
      "Epoch 117/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 133.4382 - mean_squared_error: 133.4382 - val_loss: 153.5122 - val_mean_squared_error: 153.5122\n",
      "Epoch 118/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 132.2395 - mean_squared_error: 132.2395 - val_loss: 156.3140 - val_mean_squared_error: 156.3140\n",
      "Epoch 119/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 132.9862 - mean_squared_error: 132.9862 - val_loss: 154.8931 - val_mean_squared_error: 154.8931\n",
      "Epoch 120/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 131.9915 - mean_squared_error: 131.9915 - val_loss: 166.4286 - val_mean_squared_error: 166.4286\n",
      "Epoch 121/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 134.8138 - mean_squared_error: 134.8138 - val_loss: 139.4804 - val_mean_squared_error: 139.4804\n",
      "Epoch 122/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 132.3135 - mean_squared_error: 132.3135 - val_loss: 139.8373 - val_mean_squared_error: 139.8373\n",
      "Epoch 123/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 133.2381 - mean_squared_error: 133.2381 - val_loss: 164.2435 - val_mean_squared_error: 164.2435\n",
      "Epoch 124/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 131.4266 - mean_squared_error: 131.4266 - val_loss: 158.1918 - val_mean_squared_error: 158.1918\n",
      "Epoch 125/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 131.3612 - mean_squared_error: 131.3612 - val_loss: 153.5065 - val_mean_squared_error: 153.5065\n",
      "Epoch 126/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 130.8629 - mean_squared_error: 130.8629 - val_loss: 138.7907 - val_mean_squared_error: 138.7907\n",
      "Epoch 127/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 130.7704 - mean_squared_error: 130.7704 - val_loss: 142.9222 - val_mean_squared_error: 142.9222\n",
      "Epoch 128/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 131.4642 - mean_squared_error: 131.4642 - val_loss: 151.9117 - val_mean_squared_error: 151.9117\n",
      "Epoch 129/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 129.5993 - mean_squared_error: 129.5993 - val_loss: 154.5947 - val_mean_squared_error: 154.5947\n",
      "Epoch 130/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 130.3509 - mean_squared_error: 130.3509 - val_loss: 148.3626 - val_mean_squared_error: 148.3626\n",
      "Epoch 131/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 128.4641 - mean_squared_error: 128.4641 - val_loss: 135.6575 - val_mean_squared_error: 135.6575\n",
      "Epoch 132/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 129.6849 - mean_squared_error: 129.6849 - val_loss: 151.7629 - val_mean_squared_error: 151.7629\n",
      "Epoch 133/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 128.6307 - mean_squared_error: 128.6307 - val_loss: 159.9508 - val_mean_squared_error: 159.9508\n",
      "Epoch 134/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 128.7891 - mean_squared_error: 128.7891 - val_loss: 161.2441 - val_mean_squared_error: 161.2441\n",
      "Epoch 135/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 129.1837 - mean_squared_error: 129.1837 - val_loss: 152.3918 - val_mean_squared_error: 152.3918\n",
      "Epoch 136/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 128.1283 - mean_squared_error: 128.1283 - val_loss: 147.3853 - val_mean_squared_error: 147.3853\n",
      "Epoch 137/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 127.4109 - mean_squared_error: 127.4109 - val_loss: 148.4760 - val_mean_squared_error: 148.4760\n",
      "Epoch 138/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 127.6523 - mean_squared_error: 127.6523 - val_loss: 139.5111 - val_mean_squared_error: 139.5111\n",
      "Epoch 139/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 127.2353 - mean_squared_error: 127.2353 - val_loss: 150.2492 - val_mean_squared_error: 150.2492\n",
      "Epoch 140/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 126.8966 - mean_squared_error: 126.8966 - val_loss: 139.9741 - val_mean_squared_error: 139.9741\n",
      "Epoch 141/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 127.1994 - mean_squared_error: 127.1994 - val_loss: 134.3150 - val_mean_squared_error: 134.3150\n",
      "Epoch 142/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 128.3884 - mean_squared_error: 128.3884 - val_loss: 138.8510 - val_mean_squared_error: 138.8510\n",
      "Epoch 143/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 125.9827 - mean_squared_error: 125.9827 - val_loss: 142.8711 - val_mean_squared_error: 142.8711\n",
      "Epoch 144/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 127.2512 - mean_squared_error: 127.2512 - val_loss: 142.9829 - val_mean_squared_error: 142.9829\n",
      "Epoch 145/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 126.4453 - mean_squared_error: 126.4453 - val_loss: 157.0277 - val_mean_squared_error: 157.0277\n",
      "Epoch 146/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 125.4402 - mean_squared_error: 125.4402 - val_loss: 142.2920 - val_mean_squared_error: 142.2920\n",
      "Epoch 147/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 124.0958 - mean_squared_error: 124.0958 - val_loss: 141.5256 - val_mean_squared_error: 141.5256\n",
      "Epoch 148/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 126.6967 - mean_squared_error: 126.6967 - val_loss: 149.9724 - val_mean_squared_error: 149.9724\n",
      "Epoch 149/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 126.4051 - mean_squared_error: 126.4051 - val_loss: 140.8820 - val_mean_squared_error: 140.8820\n",
      "Epoch 150/400\n",
      "9350/9350 [==============================] - 0s 14us/step - loss: 124.7739 - mean_squared_error: 124.7739 - val_loss: 143.8109 - val_mean_squared_error: 143.8109\n",
      "Epoch 151/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 124.9226 - mean_squared_error: 124.9226 - val_loss: 136.4629 - val_mean_squared_error: 136.4629\n",
      "Epoch 152/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 124.1732 - mean_squared_error: 124.1732 - val_loss: 149.0859 - val_mean_squared_error: 149.0859\n",
      "Epoch 153/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 124.5479 - mean_squared_error: 124.5479 - val_loss: 140.1621 - val_mean_squared_error: 140.1621\n",
      "Epoch 154/400\n",
      "9350/9350 [==============================] - 0s 14us/step - loss: 124.7012 - mean_squared_error: 124.7012 - val_loss: 147.5350 - val_mean_squared_error: 147.5350\n",
      "Epoch 155/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 123.3208 - mean_squared_error: 123.3208 - val_loss: 139.2561 - val_mean_squared_error: 139.2561\n",
      "Epoch 156/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 123.1375 - mean_squared_error: 123.1375 - val_loss: 155.8657 - val_mean_squared_error: 155.8657\n",
      "Epoch 157/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 124.0590 - mean_squared_error: 124.0590 - val_loss: 147.5068 - val_mean_squared_error: 147.5068\n",
      "Epoch 158/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 123.3019 - mean_squared_error: 123.3019 - val_loss: 155.2915 - val_mean_squared_error: 155.2915\n",
      "Epoch 159/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 123.2251 - mean_squared_error: 123.2251 - val_loss: 143.8181 - val_mean_squared_error: 143.8181\n",
      "Epoch 160/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 122.0595 - mean_squared_error: 122.0595 - val_loss: 148.6955 - val_mean_squared_error: 148.6955\n",
      "Epoch 161/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 120.6790 - mean_squared_error: 120.6790 - val_loss: 141.8977 - val_mean_squared_error: 141.8977\n",
      "Epoch 162/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 120.9041 - mean_squared_error: 120.9041 - val_loss: 140.6960 - val_mean_squared_error: 140.6960\n",
      "Epoch 163/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 122.1363 - mean_squared_error: 122.1363 - val_loss: 134.9742 - val_mean_squared_error: 134.9742\n",
      "Epoch 164/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 122.4466 - mean_squared_error: 122.4466 - val_loss: 137.0530 - val_mean_squared_error: 137.0530\n",
      "Epoch 165/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 121.0390 - mean_squared_error: 121.0390 - val_loss: 144.3411 - val_mean_squared_error: 144.3411\n",
      "Epoch 166/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 120.4545 - mean_squared_error: 120.4545 - val_loss: 140.8899 - val_mean_squared_error: 140.8899\n",
      "Epoch 167/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 121.3588 - mean_squared_error: 121.3588 - val_loss: 138.3719 - val_mean_squared_error: 138.3719\n",
      "Epoch 168/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 121.0815 - mean_squared_error: 121.0815 - val_loss: 151.4771 - val_mean_squared_error: 151.4771\n",
      "Epoch 169/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 120.2828 - mean_squared_error: 120.2828 - val_loss: 155.9536 - val_mean_squared_error: 155.9536\n",
      "Epoch 170/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 119.2544 - mean_squared_error: 119.2544 - val_loss: 143.0221 - val_mean_squared_error: 143.0221\n",
      "Epoch 171/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 120.8356 - mean_squared_error: 120.8356 - val_loss: 160.4828 - val_mean_squared_error: 160.4828\n",
      "Epoch 172/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 120.0706 - mean_squared_error: 120.0706 - val_loss: 158.5849 - val_mean_squared_error: 158.5849\n",
      "Epoch 173/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 118.5623 - mean_squared_error: 118.5623 - val_loss: 141.0042 - val_mean_squared_error: 141.0042\n",
      "Epoch 174/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 119.7198 - mean_squared_error: 119.7198 - val_loss: 138.1822 - val_mean_squared_error: 138.1822\n",
      "Epoch 175/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 119.8882 - mean_squared_error: 119.8882 - val_loss: 136.3807 - val_mean_squared_error: 136.3807\n",
      "Epoch 176/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 118.8333 - mean_squared_error: 118.8333 - val_loss: 139.3477 - val_mean_squared_error: 139.3477\n",
      "Epoch 177/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 120.0654 - mean_squared_error: 120.0654 - val_loss: 145.9133 - val_mean_squared_error: 145.9133\n",
      "Epoch 178/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 119.2567 - mean_squared_error: 119.2567 - val_loss: 143.5176 - val_mean_squared_error: 143.5176\n",
      "Epoch 179/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 118.1390 - mean_squared_error: 118.1390 - val_loss: 141.4831 - val_mean_squared_error: 141.4831\n",
      "Epoch 180/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 118.0827 - mean_squared_error: 118.0827 - val_loss: 145.9984 - val_mean_squared_error: 145.9984\n",
      "Epoch 181/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 118.7813 - mean_squared_error: 118.7813 - val_loss: 143.5305 - val_mean_squared_error: 143.5305\n",
      "Epoch 182/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 117.3451 - mean_squared_error: 117.3451 - val_loss: 162.5469 - val_mean_squared_error: 162.5469\n",
      "Epoch 183/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 117.7926 - mean_squared_error: 117.7926 - val_loss: 137.9224 - val_mean_squared_error: 137.9224\n",
      "Epoch 184/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 117.7089 - mean_squared_error: 117.7089 - val_loss: 138.9948 - val_mean_squared_error: 138.9948\n",
      "Epoch 185/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 117.7046 - mean_squared_error: 117.7046 - val_loss: 139.9606 - val_mean_squared_error: 139.9606\n",
      "Epoch 186/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 116.7188 - mean_squared_error: 116.7188 - val_loss: 135.9463 - val_mean_squared_error: 135.9463\n",
      "Epoch 187/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 117.6528 - mean_squared_error: 117.6528 - val_loss: 135.9187 - val_mean_squared_error: 135.9187\n",
      "Epoch 188/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 116.5414 - mean_squared_error: 116.5414 - val_loss: 148.7724 - val_mean_squared_error: 148.7724\n",
      "Epoch 189/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 115.4401 - mean_squared_error: 115.4401 - val_loss: 146.0391 - val_mean_squared_error: 146.0391\n",
      "Epoch 190/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 117.6628 - mean_squared_error: 117.6628 - val_loss: 156.0635 - val_mean_squared_error: 156.0635\n",
      "Epoch 191/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 116.2341 - mean_squared_error: 116.2341 - val_loss: 148.8890 - val_mean_squared_error: 148.8890\n",
      "Epoch 192/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 116.5601 - mean_squared_error: 116.5601 - val_loss: 135.4258 - val_mean_squared_error: 135.4258\n",
      "Epoch 193/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 116.3559 - mean_squared_error: 116.3559 - val_loss: 144.1619 - val_mean_squared_error: 144.1619\n",
      "Epoch 194/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 116.5919 - mean_squared_error: 116.5919 - val_loss: 140.5248 - val_mean_squared_error: 140.5248\n",
      "Epoch 195/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 116.2741 - mean_squared_error: 116.2741 - val_loss: 134.2083 - val_mean_squared_error: 134.2083\n",
      "Epoch 196/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 116.4960 - mean_squared_error: 116.4960 - val_loss: 142.8819 - val_mean_squared_error: 142.8819\n",
      "Epoch 197/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 115.6286 - mean_squared_error: 115.6286 - val_loss: 137.6944 - val_mean_squared_error: 137.6944\n",
      "Epoch 198/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 115.5181 - mean_squared_error: 115.5181 - val_loss: 139.0663 - val_mean_squared_error: 139.0663\n",
      "Epoch 199/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 114.1213 - mean_squared_error: 114.1213 - val_loss: 155.6765 - val_mean_squared_error: 155.6765\n",
      "Epoch 200/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 115.1867 - mean_squared_error: 115.1867 - val_loss: 133.6911 - val_mean_squared_error: 133.6911\n",
      "Epoch 201/400\n",
      "9350/9350 [==============================] - 0s 10us/step - loss: 114.9742 - mean_squared_error: 114.9742 - val_loss: 150.3093 - val_mean_squared_error: 150.3093\n",
      "Epoch 202/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 117.3193 - mean_squared_error: 117.3193 - val_loss: 155.6451 - val_mean_squared_error: 155.6451\n",
      "Epoch 203/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 113.3647 - mean_squared_error: 113.3647 - val_loss: 146.5403 - val_mean_squared_error: 146.5403\n",
      "Epoch 204/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 114.2447 - mean_squared_error: 114.2447 - val_loss: 149.5632 - val_mean_squared_error: 149.5632\n",
      "Epoch 205/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 113.5507 - mean_squared_error: 113.5507 - val_loss: 139.4700 - val_mean_squared_error: 139.4700\n",
      "Epoch 206/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 113.8252 - mean_squared_error: 113.8252 - val_loss: 138.8444 - val_mean_squared_error: 138.8444\n",
      "Epoch 207/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 113.4578 - mean_squared_error: 113.4578 - val_loss: 131.2152 - val_mean_squared_error: 131.2152\n",
      "Epoch 208/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 114.3639 - mean_squared_error: 114.3639 - val_loss: 144.3006 - val_mean_squared_error: 144.3006\n",
      "Epoch 209/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 112.7141 - mean_squared_error: 112.7141 - val_loss: 144.6928 - val_mean_squared_error: 144.6928\n",
      "Epoch 210/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 113.9294 - mean_squared_error: 113.9294 - val_loss: 140.6768 - val_mean_squared_error: 140.6768\n",
      "Epoch 211/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 112.3750 - mean_squared_error: 112.3750 - val_loss: 135.6927 - val_mean_squared_error: 135.6927\n",
      "Epoch 212/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 113.0881 - mean_squared_error: 113.0881 - val_loss: 135.4882 - val_mean_squared_error: 135.4882\n",
      "Epoch 213/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 112.1809 - mean_squared_error: 112.1809 - val_loss: 146.6053 - val_mean_squared_error: 146.6053\n",
      "Epoch 214/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 111.3992 - mean_squared_error: 111.3992 - val_loss: 139.4850 - val_mean_squared_error: 139.4850\n",
      "Epoch 215/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 112.6765 - mean_squared_error: 112.6765 - val_loss: 141.4837 - val_mean_squared_error: 141.4837\n",
      "Epoch 216/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 114.1982 - mean_squared_error: 114.1982 - val_loss: 131.7134 - val_mean_squared_error: 131.7134\n",
      "Epoch 217/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 113.8518 - mean_squared_error: 113.8518 - val_loss: 152.1331 - val_mean_squared_error: 152.1331\n",
      "Epoch 218/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 111.1318 - mean_squared_error: 111.1318 - val_loss: 137.3465 - val_mean_squared_error: 137.3465\n",
      "Epoch 219/400\n",
      "9350/9350 [==============================] - 0s 14us/step - loss: 112.3515 - mean_squared_error: 112.3515 - val_loss: 151.6084 - val_mean_squared_error: 151.6084\n",
      "Epoch 220/400\n",
      "9350/9350 [==============================] - 0s 14us/step - loss: 110.7963 - mean_squared_error: 110.7963 - val_loss: 157.2548 - val_mean_squared_error: 157.2548\n",
      "Epoch 221/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 110.6284 - mean_squared_error: 110.6284 - val_loss: 155.3903 - val_mean_squared_error: 155.3903\n",
      "Epoch 222/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 111.7703 - mean_squared_error: 111.7703 - val_loss: 159.8499 - val_mean_squared_error: 159.8499\n",
      "Epoch 223/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 110.1868 - mean_squared_error: 110.1868 - val_loss: 149.9409 - val_mean_squared_error: 149.9409\n",
      "Epoch 224/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 110.9813 - mean_squared_error: 110.9813 - val_loss: 139.0177 - val_mean_squared_error: 139.0177\n",
      "Epoch 225/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 111.9911 - mean_squared_error: 111.9911 - val_loss: 141.3097 - val_mean_squared_error: 141.3097\n",
      "Epoch 226/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 110.0594 - mean_squared_error: 110.0594 - val_loss: 157.1088 - val_mean_squared_error: 157.1088\n",
      "Epoch 227/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 110.4128 - mean_squared_error: 110.4128 - val_loss: 139.5937 - val_mean_squared_error: 139.5937\n",
      "Epoch 228/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 110.3189 - mean_squared_error: 110.3189 - val_loss: 143.4882 - val_mean_squared_error: 143.4882\n",
      "Epoch 229/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 109.5304 - mean_squared_error: 109.5304 - val_loss: 144.3526 - val_mean_squared_error: 144.3526\n",
      "Epoch 230/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 108.0913 - mean_squared_error: 108.0913 - val_loss: 141.8285 - val_mean_squared_error: 141.8285\n",
      "Epoch 231/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 109.6649 - mean_squared_error: 109.6649 - val_loss: 146.6781 - val_mean_squared_error: 146.6781\n",
      "Epoch 232/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 108.3199 - mean_squared_error: 108.3199 - val_loss: 146.0334 - val_mean_squared_error: 146.0334\n",
      "Epoch 233/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 109.8713 - mean_squared_error: 109.8713 - val_loss: 148.5705 - val_mean_squared_error: 148.5705\n",
      "Epoch 234/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 107.2925 - mean_squared_error: 107.2925 - val_loss: 141.7917 - val_mean_squared_error: 141.7917\n",
      "Epoch 235/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 109.3148 - mean_squared_error: 109.3148 - val_loss: 150.8067 - val_mean_squared_error: 150.8067\n",
      "Epoch 236/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 107.2712 - mean_squared_error: 107.2712 - val_loss: 143.2567 - val_mean_squared_error: 143.2567\n",
      "Epoch 237/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 108.7081 - mean_squared_error: 108.7081 - val_loss: 135.6252 - val_mean_squared_error: 135.6252\n",
      "Epoch 238/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 108.1459 - mean_squared_error: 108.1459 - val_loss: 143.0968 - val_mean_squared_error: 143.0968\n",
      "Epoch 239/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 108.1697 - mean_squared_error: 108.1697 - val_loss: 141.4200 - val_mean_squared_error: 141.4200\n",
      "Epoch 240/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 108.6192 - mean_squared_error: 108.6192 - val_loss: 139.6087 - val_mean_squared_error: 139.6087\n",
      "Epoch 241/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 108.4994 - mean_squared_error: 108.4994 - val_loss: 148.1799 - val_mean_squared_error: 148.1799\n",
      "Epoch 242/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 108.2430 - mean_squared_error: 108.2430 - val_loss: 149.1966 - val_mean_squared_error: 149.1966\n",
      "Epoch 243/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 108.0842 - mean_squared_error: 108.0842 - val_loss: 136.5249 - val_mean_squared_error: 136.5249\n",
      "Epoch 244/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 108.3019 - mean_squared_error: 108.3019 - val_loss: 133.5245 - val_mean_squared_error: 133.5245\n",
      "Epoch 245/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 107.3612 - mean_squared_error: 107.3612 - val_loss: 138.3957 - val_mean_squared_error: 138.3957\n",
      "Epoch 246/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 107.3002 - mean_squared_error: 107.3002 - val_loss: 144.2716 - val_mean_squared_error: 144.2716\n",
      "Epoch 247/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 106.8970 - mean_squared_error: 106.8970 - val_loss: 142.3098 - val_mean_squared_error: 142.3098\n",
      "Epoch 248/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 106.6933 - mean_squared_error: 106.6933 - val_loss: 135.2357 - val_mean_squared_error: 135.2357\n",
      "Epoch 249/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 105.3966 - mean_squared_error: 105.3966 - val_loss: 148.2241 - val_mean_squared_error: 148.2241\n",
      "Epoch 250/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 105.9841 - mean_squared_error: 105.9841 - val_loss: 155.7279 - val_mean_squared_error: 155.7279\n",
      "Epoch 251/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 107.1982 - mean_squared_error: 107.1982 - val_loss: 140.7764 - val_mean_squared_error: 140.7764\n",
      "Epoch 252/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 104.6347 - mean_squared_error: 104.6347 - val_loss: 141.4852 - val_mean_squared_error: 141.4852\n",
      "Epoch 253/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 105.0097 - mean_squared_error: 105.0097 - val_loss: 135.5606 - val_mean_squared_error: 135.5606\n",
      "Epoch 254/400\n",
      "9350/9350 [==============================] - 0s 14us/step - loss: 104.7856 - mean_squared_error: 104.7856 - val_loss: 140.5115 - val_mean_squared_error: 140.5115\n",
      "Epoch 255/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 104.5501 - mean_squared_error: 104.5501 - val_loss: 143.8922 - val_mean_squared_error: 143.8922\n",
      "Epoch 256/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 105.9721 - mean_squared_error: 105.9721 - val_loss: 143.3936 - val_mean_squared_error: 143.3936\n",
      "Epoch 257/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 104.2856 - mean_squared_error: 104.2856 - val_loss: 146.8131 - val_mean_squared_error: 146.8131\n",
      "Epoch 258/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 105.6239 - mean_squared_error: 105.6239 - val_loss: 132.4471 - val_mean_squared_error: 132.4471\n",
      "Epoch 259/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 104.4984 - mean_squared_error: 104.4984 - val_loss: 151.9436 - val_mean_squared_error: 151.9436\n",
      "Epoch 260/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 106.2258 - mean_squared_error: 106.2258 - val_loss: 150.7037 - val_mean_squared_error: 150.7037\n",
      "Epoch 261/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 103.1413 - mean_squared_error: 103.1413 - val_loss: 136.1139 - val_mean_squared_error: 136.1139\n",
      "Epoch 262/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 104.6184 - mean_squared_error: 104.6184 - val_loss: 143.1852 - val_mean_squared_error: 143.1852\n",
      "Epoch 263/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 104.5831 - mean_squared_error: 104.5831 - val_loss: 150.4999 - val_mean_squared_error: 150.4999\n",
      "Epoch 264/400\n",
      "9350/9350 [==============================] - 0s 15us/step - loss: 104.8700 - mean_squared_error: 104.8700 - val_loss: 142.2265 - val_mean_squared_error: 142.2265\n",
      "Epoch 265/400\n",
      "9350/9350 [==============================] - 0s 14us/step - loss: 103.4206 - mean_squared_error: 103.4206 - val_loss: 145.7852 - val_mean_squared_error: 145.7852\n",
      "Epoch 266/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 103.2816 - mean_squared_error: 103.2816 - val_loss: 144.1515 - val_mean_squared_error: 144.1515\n",
      "Epoch 267/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 103.5348 - mean_squared_error: 103.5348 - val_loss: 146.5227 - val_mean_squared_error: 146.5227\n",
      "Epoch 268/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 102.5171 - mean_squared_error: 102.5171 - val_loss: 141.8142 - val_mean_squared_error: 141.8142\n",
      "Epoch 269/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 103.2558 - mean_squared_error: 103.2558 - val_loss: 132.4614 - val_mean_squared_error: 132.4614\n",
      "Epoch 270/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 106.0617 - mean_squared_error: 106.0617 - val_loss: 149.3512 - val_mean_squared_error: 149.3512\n",
      "Epoch 271/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 102.4345 - mean_squared_error: 102.4345 - val_loss: 139.7798 - val_mean_squared_error: 139.7798\n",
      "Epoch 272/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 102.1976 - mean_squared_error: 102.1976 - val_loss: 139.0525 - val_mean_squared_error: 139.0525\n",
      "Epoch 273/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 102.5362 - mean_squared_error: 102.5362 - val_loss: 140.8128 - val_mean_squared_error: 140.8128\n",
      "Epoch 274/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 101.7567 - mean_squared_error: 101.7567 - val_loss: 143.0493 - val_mean_squared_error: 143.0493\n",
      "Epoch 275/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 101.7200 - mean_squared_error: 101.7200 - val_loss: 131.7270 - val_mean_squared_error: 131.7270\n",
      "Epoch 276/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 100.9169 - mean_squared_error: 100.9169 - val_loss: 138.4484 - val_mean_squared_error: 138.4484\n",
      "Epoch 277/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 101.4158 - mean_squared_error: 101.4158 - val_loss: 139.6997 - val_mean_squared_error: 139.6997\n",
      "Epoch 278/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 100.6855 - mean_squared_error: 100.6855 - val_loss: 138.6877 - val_mean_squared_error: 138.6877\n",
      "Epoch 279/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 100.4031 - mean_squared_error: 100.4031 - val_loss: 138.9465 - val_mean_squared_error: 138.9465\n",
      "Epoch 280/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 103.1216 - mean_squared_error: 103.1216 - val_loss: 136.2674 - val_mean_squared_error: 136.2674\n",
      "Epoch 281/400\n",
      "9350/9350 [==============================] - 0s 12us/step - loss: 101.7636 - mean_squared_error: 101.7636 - val_loss: 142.7622 - val_mean_squared_error: 142.7622\n",
      "Epoch 282/400\n",
      "9350/9350 [==============================] - 0s 13us/step - loss: 100.6494 - mean_squared_error: 100.6494 - val_loss: 147.3215 - val_mean_squared_error: 147.3215\n",
      "Epoch 283/400\n",
      "9350/9350 [==============================] - 0s 11us/step - loss: 101.6840 - mean_squared_error: 101.6840 - val_loss: 138.0606 - val_mean_squared_error: 138.0606\n",
      "Epoch 284/400\n",
      "4608/9350 [=============>................] - ETA: 0s - loss: 101.8183 - mean_squared_error: 101.8183"
     ]
    }
   ],
   "source": [
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=EPOCHS, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best results: \n",
    "-------------\n",
    "0.1, 24-10% dropout-12-8-1 batch 64 and learning rate 0.1\n",
    "\n",
    "126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
